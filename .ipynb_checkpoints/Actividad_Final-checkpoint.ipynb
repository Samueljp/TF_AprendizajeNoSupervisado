{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlT8OiBdJFu0"
   },
   "source": [
    "# AGRUPAMIENTO CONOCIDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWv2xZWqJFu2"
   },
   "source": [
    "Para la primera parte de la actividad, en la que se analizará un conjunto de datos con agrupamiento conocido, se ha decidido utilizar uno de los datasets sintéticos proporcionados. El objetivo principal será el demostrar, aprovechando las particularidades tan marcadas del dataset, como la tipología de los datos afecta a la efectividad de los distintos métodos de agrupamiento.<br>\n",
    "\n",
    "En el caso del dataset escogido \"dataset_cuatro_diferente_densidad\" la particularidad más marcada es la diferencia de densidades entre los distintos agrupamientos, lo que, como se podrá comprobar, pondrá en serias dificultades algunos de los algoritmos analizados. Si se hubieran escogido otros datos, los resultados habrían variado significativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYMrsacKJFu3"
   },
   "outputs": [],
   "source": [
    "# Se importan las distintas librerías que se usarán durante la actividad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Se declaran un grupo de funciones de evaluación intrínsecas que se utilizaran más adelante\n",
    "def medida_error(mat):\n",
    "    assign = np.sum([np.max(mat[l,:]) for l in np.arange(mat.shape[0])])\n",
    "    return 1 - assign / float(np.sum(mat))\n",
    "\n",
    "def medida_pureza(mat):\n",
    "    totales = np.sum(mat,0)/float(np.sum(mat))\n",
    "    return np.sum([totales * np.max(mat[:,k]/float(np.sum(mat[:,k]))) for k in np.arange(mat.shape[1])])\n",
    "\n",
    "def medida_precision(mat, l, k):\n",
    "    return mat[l,k]/float(np.sum(mat[:,k]))\n",
    "\n",
    "def medida_recall(mat, l, k):\n",
    "    return mat[l,k]/float(np.sum(mat[l,:]))\n",
    "\n",
    "def medida_f1_especifica(mat, l, k):\n",
    "    prec = medida_precision(mat, l, k)\n",
    "    rec = medida_recall(mat, l, k)\n",
    "    if (prec+rec)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * prec * rec / (prec + rec)\n",
    "\n",
    "def medida_f1(mat):\n",
    "    totales = np.sum(mat,1)/float(np.sum(mat))\n",
    "    assign = np.sum([totales[l] * np.max([medida_f1_especifica(mat, l, k) \n",
    "                                          for k in np.arange(mat.shape[1])]) \n",
    "                     for l in np.arange(mat.shape[0])])\n",
    "    return assign\n",
    "\n",
    "def medida_entropia(mat):\n",
    "    totales = np.sum(mat,0)/float(np.sum(mat))\n",
    "    relMat = mat/np.sum(mat,0)\n",
    "    logRelMat = relMat.copy()\n",
    "    logRelMat[logRelMat==0]=0.0001 # Evita el logaritmo de 0. Inofensivo pues luego desaparece al multiplicar por 0\n",
    "    logRelMat = np.log(logRelMat)\n",
    "    return -np.sum([totales[k] * np.sum([relMat[l,k]*logRelMat[l,k] \n",
    "                                         for l in np.arange(mat.shape[0])]) \n",
    "                    for k in np.arange(mat.shape[1])])\n",
    "\n",
    "# Se declara la función que se utilizará para comprobar los resultados de los distintos agrupamientos \n",
    "def intrinsic_evaluation(Dy_t, Dy_p):\n",
    "    conf_matrix = confusion_matrix(Dy_t, Dy_p)\n",
    "    entropy = medida_entropia(conf_matrix)\n",
    "    purity = medida_pureza(conf_matrix)\n",
    "    f1 = medida_f1(conf_matrix)\n",
    "    df_cm = pd.DataFrame(conf_matrix)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.title('Pureza: '  + str(round(purity, 4)) + '  F1: ' + str(round(f1, 4)) + '  Entropía: ' + str(round(entropy, 4)),\n",
    "              fontdict={'fontsize':20})\n",
    "    sn.heatmap(df_cm, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0MDtx_BJFu6"
   },
   "source": [
    "# k-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "anPNM3Q8JFu6"
   },
   "source": [
    "Como representante de agrupamiento basado en particiones se ha escogido **k-means++**, máximo representante de este tipo de agrupamiento y del clustering en general (con sus variaciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "7GDidy-gJFu7",
    "outputId": "774fccb3-fb9b-49e2-e40d-63fb81638b02",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Si se quiere asegurar la reproducibilidad de la práctica se fija la semilla aleatoria\n",
    "# Sin embargo, si lo que se busca es simular una situación real puede ser más interesante evaluar múltiples casuísticas con\n",
    "# inicializaciones distintas.\n",
    "np.random.seed(17)\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/jhernandezgonzalez/unsupervisedlearning/master/datasets/sinteticos/dataset_cuatro_diferente_densidad.csv'\n",
    "D = np.array(pd.read_csv(data_file_url,header=0))\n",
    "Dx = D[:,0:2]\n",
    "Dy = D[:,2]\n",
    "\n",
    "print('El dataset cargado tiene',Dx.size,'instancias.')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSic-BBHJFvA"
   },
   "source": [
    "*El primer paso que se realizará es la detección del número óptimo de clusters. Para ello se utilizarán dos medidas de evaluación intrínseca (ancho de silueta y índice de Calinski-Harabasz) y el procedimiento del codo.*<br>\n",
    "\n",
    "*En este estudio se utilizaran principalmente estas 2 medidas intrínsecas para la parametrización debido a que no sufren demasiado por intentar evaluar clusters con distintas densidades*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "colab_type": "code",
    "id": "rUMVd2KjJFvA",
    "outputId": "18d0efed-d694-47c3-a981-f75fce428a7a"
   },
   "outputs": [],
   "source": [
    "# Compruebo que 4 es un buen número de clústers\n",
    "from sklearn.metrics import silhouette_score, calinski_harabaz_score\n",
    "\n",
    "rsilueta = np.zeros(9)\n",
    "rcalinski = np.zeros(9)\n",
    "\n",
    "for k in np.arange(2,11):\n",
    "    modelo = KMeans(n_clusters=k, init='k-means++')\n",
    "    modelo = modelo.fit(Dx)\n",
    "    Dyp_sk = modelo.predict(Dx)\n",
    "    cDx_sk = modelo.cluster_centers_\n",
    "    rsilueta[k-2] = silhouette_score(Dx, Dyp_sk)\n",
    "    rcalinski[k-2] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot( np.arange(2,11), rsilueta, linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Número de clústeres\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot( np.arange(2,11), rcalinski, linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Número de clústeres\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BG69wEkJJFvD"
   },
   "source": [
    "*Si se observan las medidas de ancho de silueta para las distintas cantidades de clusters se puede ver el cambio de pendiente anunciado por la regla del codo en k=4. A su vez, la mejor medida de Calinski-Harabasz también se encuentra en k=4 por lo que se escoge este número de clusters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnymDEerJFvF"
   },
   "outputs": [],
   "source": [
    "# Se inicializa KMeans con el número de clústeres a buscar\n",
    "modelo = KMeans(n_clusters=4, init='k-means++')\n",
    "# Se aprende el \n",
    "modelo = modelo.fit(Dx)\n",
    "# Se predicen los clusters\n",
    "Dyp_sk = modelo.predict(Dx)\n",
    "# Se obtienen los centros de los clústeres\n",
    "cDx_sk = modelo.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "VUhBPbK-JFvH",
    "outputId": "38af3c90-4203-48ee-c208-16b117c4e53c"
   },
   "outputs": [],
   "source": [
    "# Los centros de los clusters se encuentran en\n",
    "print(cDx_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "QpK5kFwnJFvK",
    "outputId": "c9636173-3cfa-4249-c5a2-a79f5fdccefe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se muestra el resultado de las asignaciones finales\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dyp_sk)\n",
    "ax.scatter(cDx_sk[:,0],cDx_sk[:,1], marker='*', s=200, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92KCe1VlJFvM"
   },
   "source": [
    "*Finalmente se aplican las distintas medidas intrínsecas para evaluar el comportamiento del algoritmo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "qSEL1J6bJFvN",
    "outputId": "9318adcc-ac1a-4490-a740-4508fb90dfbf"
   },
   "outputs": [],
   "source": [
    "# Debido a que los valores de los clusteres reales van de 1 a 4 y que los calculados van de 0 a 3,\n",
    "# se aplica un factor de corrección para calcular la matriz de confusión.\n",
    "intrinsic_evaluation(Dy-[1], Dyp_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0ueF-NqJFvQ"
   },
   "source": [
    "*Se puede observar que los resultados del algoritmo son muy buenos debido a que los datos se adaptan perfectamente a un agrupamiento por particiones.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BUZ09toJFvQ"
   },
   "source": [
    "# Clustering Jerárquico Aglomerativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YF5PNNxtJFvR"
   },
   "source": [
    "Como ejemplo de agrupamiento jerárquico se utilizará la aproximación aglomerativa debido a que hasta el momento la divisiva raramente se utiliza en aplicaciones reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3490
    },
    "colab_type": "code",
    "id": "TGrN4bd1JFvS",
    "outputId": "7c8e89aa-d716-4724-9223-098377208e57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster, cut_tree, dendrogram\n",
    "\n",
    "# Se generan 3 modelos utilizando los distintos tipos de cálculo de disimilitud intercluster estudiados en clase\n",
    "modelo_single = linkage(Dx, 'single')   # disimilitud mínima\n",
    "modelo_completo = linkage(Dx, 'complete') # disimilitud máxima\n",
    "modelo_average = linkage(Dx, 'average')  # disimilitud media\n",
    "\n",
    "plt.figure(figsize=(50, 20))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo_single)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(50, 20))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo_completo)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(50, 20))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo_average)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZoHjP_pJFvV"
   },
   "source": [
    "*En este caso se compararán las tres disimilitudes estudiadas en clase y por ello fijaremos el número de clusters en 4, como se ha podido ver en el anterior apartado.*<br>\n",
    "\n",
    "*Para empezar se muestran visualmente los resultados.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "vDNzUV0TJFvW",
    "outputId": "f6464b8c-9279-4c7b-d85e-62f2611f5b92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo_single, n_clusters=4).flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0U7yISGqJFvZ"
   },
   "source": [
    "*No funciona muy bien. Los puntos amarillo y verde los considera un clúster y no logra separar.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "XJtVp3hSJFva",
    "outputId": "2d7714d8-1b37-4b4d-8903-746c85c7ccb9"
   },
   "outputs": [],
   "source": [
    "plt.scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo_completo, n_clusters=4).flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqaAGFObJFvd"
   },
   "source": [
    "*No funciona muy bien. Divide el cluster inferior de la derecha antes que los de la izquierda*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "aXXc9gJTJFve",
    "outputId": "7f0deab9-d239-437b-a206-76cac12e93f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo_average, n_clusters=4).flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SVNYBxNJFvj"
   },
   "source": [
    "*No funciona muy bien. El punto amarillo lo considera un clúster y no logra separar el de la izquierda.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWJ0DVyuJFvk"
   },
   "source": [
    "*En los dos últimos ejemplos parecería que si se aumentara el número de clusters el resultado podría ser mejor. Se ha probado y no es así, el algoritmo tiende a dividir los clusters de la derecha en más partes antes que los dos de la izquierda.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_5Tg9zCJFvl"
   },
   "outputs": [],
   "source": [
    "# La siguiente función llega a los mismos resultados \n",
    "#def plot_varios(Dx,Dy,K):\n",
    "#    fig, ax = plt.subplots(1,4, figsize=(20,5))\n",
    "#    ax[0].scatter(Dx[:,0], Dx[:,1], c=Dy)\n",
    "#    ax[0].set_title('Datos originales')\n",
    "\n",
    "#    modelo = linkage(Dx, 'single')\n",
    "#    ax[1].scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters = K).flatten())\n",
    "#    ax[1].set_title('Disimilitud mínima')\n",
    "    \n",
    "#    modelo = linkage(Dx, 'complete')\n",
    "#    ax[2].scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters = K).flatten())\n",
    "#    ax[2].set_title('Disimilitud máxima')\n",
    "    \n",
    "#    modelo = linkage(Dx, 'average')\n",
    "#    ax[3].scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters = K).flatten())\n",
    "#    ax[3].set_title('Disimilitud media')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9XpDOvBJFvq"
   },
   "outputs": [],
   "source": [
    "#plot_varios(Dx,Dy,4) # Ninguna distancia funciona muy bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "PpnD1yjyJFvt",
    "outputId": "e27cd02a-8ccb-4e98-9294-dc01883274f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se utiliza el modelo que ha devuelto mejores resultados (modelo_average) para la evaluación intrínseca. \n",
    "intrinsic_evaluation(Dy-[1], cut_tree(modelo_average, n_clusters=4).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxilSqCpJFvw"
   },
   "source": [
    "*En este caso las medidas son significativamente que para Kmeans++. La poca densidad del cluster de arriba a la derecha contra la gran proximidad de los de la izquierda hacen que los algoritmos jerárquicos no sean una buena opción.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXO1KlkJJFvw"
   },
   "source": [
    "# Agrupamiento Espectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9cEJmafJFvx"
   },
   "source": [
    "Como caso paradigmático de agrupamiento espectral se utilizará un grafo con K vecinos más cercanos y una laplaciana normalizada (utilizada en la función SpectralClustering de sklearn).<br>\n",
    "\n",
    "Para empezar, buscamos el número óptimo de vecinos para el KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1892
    },
    "colab_type": "code",
    "id": "yRRR9OyKJFvy",
    "outputId": "86fbd3a8-5ce9-4306-8e5a-1725552a9bcb"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "rSpectral_cal = {}\n",
    "rSpectral_sil = {}\n",
    "for K in np.arange(2,9):\n",
    "    for knn in np.arange(7,20,1):\n",
    "        modelo = SpectralClustering(n_clusters = K, \n",
    "                                    affinity = 'nearest_neighbors', n_neighbors = knn,\n",
    "                                    random_state = 0)\n",
    "        Dyp_sk = modelo.fit_predict(Dx)\n",
    "        rSpectral_cal[str(K) + '_' + str(knn)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "        rSpectral_sil[str(K) + '_' + str(knn)] = silhouette_score(Dx, Dyp_sk)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rSpectral_cal.keys(), rSpectral_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Nº clusters-Vecinos)\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rSpectral_sil.keys(), rSpectral_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Nº clusters-Vecinos)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVXOeHJCJFv2"
   },
   "source": [
    "*Se observa que para pocos vecinos el algoritmo no es capaz de crear un grafo totalmente conectado.*<br>\n",
    "\n",
    "*También se ve que de 18 vecinos en adelante, en ningún caso el algoritmo no mejora.*<br>\n",
    "\n",
    "*Se provaran dos configuraciones, 2 clusters y 12 vecinos (el resultado sería el mismo pero con menos vecinos el grafo no queda conectado) y 4 clusters y 15 vecinos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "EnwJ6RQjJFv3",
    "outputId": "4225ed0d-f86d-49bb-b3c9-c022644403b4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(20,5))\n",
    "\n",
    "clustering_2_12 = SpectralClustering(n_clusters = 2, \n",
    "                                affinity = 'nearest_neighbors', n_neighbors = 12,\n",
    "                                random_state = 0).fit(Dx)\n",
    "ax[0].scatter(Dx[:,0], Dx[:,1], c=clustering_2_12.labels_)\n",
    "ax[0].set_title('2 Clusters con 12 vecinos')\n",
    "    \n",
    "clustering_4_15 = SpectralClustering(n_clusters = 4, \n",
    "                                affinity = 'nearest_neighbors', n_neighbors = 15,\n",
    "                                random_state = 0).fit(Dx)\n",
    "ax[1].scatter(Dx[:,0], Dx[:,1], c=clustering_4_15.labels_)\n",
    "ax[1].set_title('4 Clusters con 15 vecinos')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "aNnsKINfJFv5",
    "outputId": "acf2b14f-acda-40d3-d2d0-88cd02ed1e6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se utiliza el modelo con K=2 y knn=12 visto arriba\n",
    "intrinsic_evaluation(Dy-[1], clustering_2_12.fit_predict(Dx).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "Yp2X-VS8JFv7",
    "outputId": "7ee986ff-a48b-4b9e-9343-2dda7358d05c"
   },
   "outputs": [],
   "source": [
    "# Se utiliza el modelo con K=4 y knn=15 visto arriba\n",
    "intrinsic_evaluation(Dy-[1], clustering_4_15.fit_predict(Dx).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_jGf9rUJFv-"
   },
   "source": [
    "# Agrupamiento basado en densidad - DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GlDHmNjJFv_"
   },
   "source": [
    "En el caso del agrupamiento basado en densidad, al haber visto tres métodos con propiedades significativamente distintas se ha decidido aplicar los 3 y realizar ajuste de parámetros hasta llegar a la mejor solución posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "colab_type": "code",
    "id": "tnJNPgCJJFv_",
    "outputId": "7a640d3c-6408-4e40-adc1-37fc98c69c94"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "rDBSCAN_cal = {}\n",
    "rDBSCAN_sil = {}\n",
    "for M in np.arange(4,20,2):\n",
    "    for eps in np.arange(4,20,2):\n",
    "        modelo = DBSCAN(eps=eps, min_samples=M)\n",
    "        Dyp_sk = modelo.fit_predict(Dx)\n",
    "        rDBSCAN_cal[str(M) + '_' + str(eps)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "        rDBSCAN_sil[str(M) + '_' + str(eps)] = silhouette_score(Dx, Dyp_sk)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rDBSCAN_cal.keys(), rDBSCAN_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Vecinos-Rango)\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rDBSCAN_sil.keys(), rDBSCAN_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Vecinos-Rango)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "fTINThK8JFwC",
    "outputId": "c722da43-bce4-4ad4-fc86-c127dfa8fa68",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eps = 12\n",
    "M = 12\n",
    "clustering = DBSCAN(eps=eps, min_samples=M).fit(Dx)\n",
    "\n",
    "# Mostrar resultados\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "ax[0].scatter(Dx[:,0], Dx[:,1], c= Dy)\n",
    "ax[1].scatter(Dx[:,0], Dx[:,1], c = clustering.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtXiYXZ7JFwG"
   },
   "source": [
    "*Se observa que ni en el mejor caso se llega a un clustering medianamente aceptable. El algoritmo solo consigue detectar 2 clústers y una gran cantidad de puntos de ruido. Esto es debido a que DBSCAN no es ni mucho menos el más adecuado para clasificar clusters con densidades distintas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlCdtoQxJFwH"
   },
   "source": [
    "# Agrupamiento basado en densidad - Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "ELGcBFrEJFwI",
    "outputId": "0a733c44-99f3-46fc-d487-d269b5d6ad81"
   },
   "outputs": [],
   "source": [
    "# Variando h (bandwidth) solo consigue separar en 3 clusters, no 4\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "rMeanShift_cal = {}\n",
    "rMeanShift_sil = {}\n",
    "for bwd in np.arange(4,81,4):\n",
    "    modelo = MeanShift(bandwidth = bwd, n_jobs=4)\n",
    "    Dyp_sk = modelo.fit_predict(Dx)\n",
    "    rMeanShift_cal[bwd] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "    rMeanShift_sil[bwd] = silhouette_score(Dx, Dyp_sk)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rMeanShift_cal.keys(), rMeanShift_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Bandwidth\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rMeanShift_sil.keys(), rMeanShift_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Vecinos-Rango)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "GTL9W0DlJFwK",
    "outputId": "e3770485-d6e2-4dc2-a8aa-c52bca6b5830"
   },
   "outputs": [],
   "source": [
    "clustering = MeanShift(bandwidth = 30).fit(Dx)\n",
    "\n",
    "# Mostrar resultados\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "ax[0].scatter(Dx[:,0], Dx[:,1], c = Dy)\n",
    "ax[1].scatter(Dx[:,0], Dx[:,1], c = clustering.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiyeNK6KJFwN"
   },
   "source": [
    "# Agrupamiento basado en densidad - Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WC4DOhqIJFwO"
   },
   "outputs": [],
   "source": [
    "# Función que se utilizará para pintar las relaciones entre los representates finales y sus representados en cada cluster\n",
    "def dibujar_clusteringAP(modelo):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ncentros = modelo.cluster_centers_indices_.size\n",
    "    colores = 'bgrcmyk'\n",
    "\n",
    "    for k in np.arange(ncentros):\n",
    "        kc = k % len(colores)\n",
    "\n",
    "        centro = Dx[modelo.cluster_centers_indices_[k],:]\n",
    "        miembros_cluster = np.where(modelo.labels_ == k)[0]\n",
    "\n",
    "        plt.scatter(Dx[miembros_cluster, 0], Dx[miembros_cluster, 1], c=colores[kc], s=3)\n",
    "        for i in miembros_cluster:\n",
    "            plt.plot([centro[0], Dx[i,0]], [centro[1], Dx[i,1]], c = colores[kc])\n",
    "\n",
    "    plt.scatter(Dx[modelo.cluster_centers_indices_,0], Dx[modelo.cluster_centers_indices_,1], \n",
    "                s=50, c = 'black')\n",
    "\n",
    "    plt.title('Núm. clústeres: %s' % ncentros)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1432
    },
    "colab_type": "code",
    "id": "iG6M53_zJFwP",
    "outputId": "b0c6346f-2820-4283-9814-787d2d4f2a67"
   },
   "outputs": [],
   "source": [
    "# He tenido que pasar un buen rato modificando el factor de aprendizaje y las preferencias hasta obtener 4 clusters\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "mSimilitud = euclidean_distances(Dx)\n",
    "mSimilitud = -mSimilitud**2\n",
    "\n",
    "rAffinity_cal = {}\n",
    "rAffinity_sil = {}\n",
    "\n",
    "for pref in np.arange(100,200,10):\n",
    "    for factor in np.arange(0.71,0.95,0.04):\n",
    "        preferencia = np.median(mSimilitud) * pref\n",
    "        np.fill_diagonal(mSimilitud, preferencia)\n",
    "        modelo = AffinityPropagation(preference=preferencia, damping=factor)\n",
    "        Dyp_sk = modelo.fit_predict(Dx)\n",
    "        # Condición para parar la iteración\n",
    "        if np.max(Dyp_sk) == -1:\n",
    "            print(\"Error: pref: %d, factor: %f \",(pref,factor))\n",
    "            break\n",
    "        rAffinity_cal[str(pref) + '_' + str(factor)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "        rAffinity_sil[str(pref) + '_' + str(factor)] = silhouette_score(Dx, Dyp_sk)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rAffinity_cal.keys(), rAffinity_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Preferencia-Factor)\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(rAffinity_sil.keys(), rAffinity_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Parámetros (Preferencia-Factor)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tmn4eeaxJFwR"
   },
   "outputs": [],
   "source": [
    "## /REVISAR/ Comento esto que creo que hay que borrarlo\n",
    "# clustering = AffinityPropagation(preference=preferencia, damping=factor).fit(Dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbXb_1OoJFwT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHwAuJ7BJFwV"
   },
   "outputs": [],
   "source": [
    "## /REVISAR/ Comento esto que creo que hay que borrarlo\n",
    "# dibujar_clusteringAP(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "fRAo_24dJFwW"
   },
   "source": [
    "# Mixtura de Gaussianas y algoritmo EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "mpO7nVAnJFwX",
    "outputId": "2136e1dc-8e7b-47ec-bd81-ad4d2e315970"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def matriz_confusion(cat_real, cat_pred):\n",
    "    cats = np.unique(cat_real)\n",
    "    clusts = np.unique(cat_pred)\n",
    "    mat = np.array([[np.sum(np.logical_and(cat_real==cats[i], cat_pred==clusts[j])) \n",
    "                     for j in np.arange(clusts.size)] \n",
    "                    for i in np.arange(cats.size)])\n",
    "    return(mat)\n",
    "\n",
    "\n",
    "def medida_error(mat):\n",
    "    assign = np.sum([np.max(mat[l,:]) for l in np.arange(mat.shape[0])])\n",
    "    return 1 - assign / float(np.sum(mat))\n",
    "\n",
    "def medida_pureza(mat):\n",
    "    totales = np.sum(mat,0)/float(np.sum(mat))\n",
    "    return np.sum([totales[k] * np.max(mat[:,k]/float(np.sum(mat[:,k]))) for k in np.arange(mat.shape[1])])\n",
    "\n",
    "def medida_precision(mat, l, k):\n",
    "    return mat[l,k]/float(np.sum(mat[:,k]))\n",
    "\n",
    "def medida_recall(mat, l, k):\n",
    "    return mat[l,k]/float(np.sum(mat[l,:]))\n",
    "\n",
    "def medida_f1_especifica(mat, l, k):\n",
    "    prec = medida_precision(mat, l, k)\n",
    "    rec = medida_recall(mat, l, k)\n",
    "    if (prec+rec)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2*prec*rec/(prec+rec)\n",
    "\n",
    "def medida_f1(mat):\n",
    "    totales = np.sum(mat,1)/float(np.sum(mat))\n",
    "    assign = np.sum([totales[l] * np.max([medida_f1_especifica(mat, l, k) \n",
    "                                          for k in np.arange(mat.shape[1])]) \n",
    "                     for l in np.arange(mat.shape[0])])\n",
    "    return assign\n",
    "\n",
    "# Se inicializa el método con el número de clústeres (componentes) a buscar\n",
    "modelo = GaussianMixture(n_components = 4, max_iter = 200)\n",
    "# Se aprende el modelo\n",
    "modelo = modelo.fit(Dx)\n",
    "# Se predicen las asignaciones a clústeres\n",
    "Dyp_sk = modelo.predict(Dx)\n",
    "\n",
    "# Medimos el rendimiento del algoritmo de ScikitLearn\n",
    "mC_sk = matriz_confusion(Dy,Dyp_sk)\n",
    "\n",
    "print('Matriz de confusión:')\n",
    "print(mC_sk)\n",
    "print('El valor del error cometido es = ', medida_error(mC_sk))\n",
    "print('La pureza del agrupamiento obtenido es = ', medida_pureza(mC_sk))\n",
    "print('El valor F1 es = ', medida_f1(mC_sk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "pG7SSDYyJFwb",
    "outputId": "b066e432-b48b-4245-fec2-1b08768abbb8"
   },
   "outputs": [],
   "source": [
    "# Mostrar resultados. Parece funcionar bien, pero hay algunos puntos que no se asignan correctamente\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "ax[0].scatter(Dx[:,0], Dx[:,1], c = Dy)\n",
    "ax[1].scatter(Dx[:,0],Dx[:,1], c=Dyp_sk)\n",
    "ax[0].set_title('Datos originales')\n",
    "ax[1].set_title('Algoritmo EM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWJeDf1uJFwf"
   },
   "source": [
    "# AGRUPAMIENTO NO CONOCIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "wzNBmYsqJFwf",
    "outputId": "eea9dc8a-29b4-4fae-fcd3-fcbfae88a6bf"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# DATASET DE AUTOS_MPG DE UCI\n",
    "url_autos = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "data_names = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','car name']\n",
    "\n",
    "response=requests.get(url_autos).content\n",
    "ds_autos=pd.read_csv(io.StringIO(response.decode('utf-8')),delim_whitespace=True,header=None, names = data_names,na_values='?')\n",
    "\n",
    "# Limpieza de las instancias con valores nulos\n",
    "ds_autos = ds_autos.dropna()\n",
    "\n",
    "# EJEMPLO DE DATOS\n",
    "ds_autos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "3IcQ0TLXJFwj",
    "outputId": "77775aa3-3660-4170-dd25-b49df3e76e7f"
   },
   "outputs": [],
   "source": [
    "# ESTADÍSTICA DEL DATASET\n",
    "ds_autos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Ivb5Ab-sJFwl",
    "outputId": "dae34de3-c987-4122-e00b-8f314f383a0e"
   },
   "outputs": [],
   "source": [
    "# Correlación entre las columnas\n",
    "ds_autos.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "99zIgqekJFwp",
    "outputId": "2479638e-0d08-4b57-f4ca-7ae7b2fb5d12"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Transformación a array de numpy eliminando el modelo del coche, origen y año\n",
    "D = np.array(ds_autos)[:,:-3]\n",
    "\n",
    "# Normalizamos los valores\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(D)\n",
    "# Dx contiene los datos normalizados\n",
    "Dx = scaler.transform(D)\n",
    "\n",
    "# Guardamos los nombres de las columnas\n",
    "columHeaders = ds_autos.columns.values[:-3]\n",
    "\n",
    "Dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-skwTGTHJFwq"
   },
   "source": [
    "## K-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "colab_type": "code",
    "id": "RC4P7Vx_JFwr",
    "outputId": "1b3ef619-7e59-4486-e722-0be90eb3a072"
   },
   "outputs": [],
   "source": [
    "# Comprobación de número de clusters adecuados\n",
    "rsilueta = np.zeros(9)\n",
    "rcalinski = np.zeros(9)\n",
    "\n",
    "for k in np.arange(2,11):\n",
    "    modelo = KMeans(n_clusters=k)\n",
    "    modelo = modelo.fit(Dx)\n",
    "    Dyp_sk = modelo.predict(Dx)\n",
    "    cDx_sk = modelo.cluster_centers_\n",
    "    rsilueta[k-2] = silhouette_score(Dx, Dyp_sk)\n",
    "    rcalinski[k-2] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot( np.arange(2,11),rsilueta, linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Número de clústeres\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot( np.arange(2,11), rcalinski, linestyle='-', marker='o')\n",
    "ax.set_xlabel(\"Número de clústeres\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBNySDkqJFww"
   },
   "source": [
    "### Resultado\n",
    "\n",
    "Con esta técnica vemos que el número de $k$ apropiado parce estar entre $k=2$ o $k=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KV1_afIJFwx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# función para dibujar la silueta\n",
    "def plot_silhouettes(X, y):\n",
    "    cluster_labels = np.unique(y)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_samples(X, y, metric='euclidean')\n",
    "    y_ax_lower = 0\n",
    "    y_ax_upper = 0\n",
    "    yticks = []\n",
    "    for i, c in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[y == c]\n",
    "        c_silhouette_vals.sort()\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "#         color = cm.jet(i / n_clusters)\n",
    "        plt.barh(\n",
    "            range(y_ax_lower, y_ax_upper),\n",
    "            c_silhouette_vals,\n",
    "            height=1.0,\n",
    "            edgecolor='none'\n",
    "        )\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2)\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color='red', linestyle='--')\n",
    "\n",
    "    plt.yticks(yticks, cluster_labels + 1)\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.xlabel('Silhouette coefficient')\n",
    "\n",
    "    plt.show() \n",
    "\n",
    "def mostrarAtributosRelevantes(Dx, Y):\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X,Y)\n",
    "    \n",
    "    df = pd.DataFrame([[x, model.feature_importances_[x], columHeaders[x]] for x in range(len(columHeaders))],columns=['indice','importancia','atributo'])\n",
    "    \n",
    "    variables = df.sort_values('importancia',ascending=False).iloc[0:3]    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    ax.bar(columHeaders,model.feature_importances_)\n",
    "    ax.set_title('Relevancia de variables para K ='+ str(len(set(Y))))\n",
    "    \n",
    "    x_param = variables.iloc[0,0]\n",
    "    y_param = variables.iloc[1,0]\n",
    "    z_param = variables.iloc[2,0]\n",
    "    \n",
    "    x_label = columHeaders[x_param]\n",
    "    y_label = columHeaders[y_param]\n",
    "    z_label = columHeaders[z_param]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(D[:,x_param],D[:,y_param], D[:,z_param], c = Y)\n",
    "\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_zlabel(z_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KiFqzO_JFw1"
   },
   "source": [
    "### Observación de resultados gráficos\n",
    "\n",
    "Intentamos sacar las variables más representativas del clasificador que parecen ser los cilindros y el desplazamiento.\n",
    "\n",
    "A medida que aumentamos el número de $k$ el valor de los parámetros para el algoritmo se va igualando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8164
    },
    "colab_type": "code",
    "id": "F3slUF0XJFw1",
    "outputId": "d8981ab6-21e4-4bab-83ed-288cda108d09"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score, silhouette_score, calinski_harabaz_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Cambio la salida por consola de los números\n",
    "np.set_printoptions(formatter={\"float_kind\": lambda x: \"%g\" % x})\n",
    "\n",
    "\n",
    "rKM_cal = {}\n",
    "rKM_sil = {}\n",
    "\n",
    "fig, ax = plt.subplots(5,2,figsize=(20,50))\n",
    "# ax[1].scatter(Dx[:,2],Dx[:,4], c=Dyp_sk)  \n",
    "\n",
    "aux_graphf = 0\n",
    "aux_graphc = 0\n",
    "\n",
    "# Se inicializa KMeans con el número de clústeres a buscar\n",
    "for nClusters in range(2,7):\n",
    "    modelo = KMeans(n_clusters=nClusters)\n",
    "    # Se aprende el \n",
    "    modelo = modelo.fit(Dx)\n",
    "    # Predicting the clusters\n",
    "    Dyp_sk = modelo.predict(Dx)\n",
    "    result = modelo.labels_\n",
    "    # Obtener los centros de los clústeres\n",
    "    cDx_sk = modelo.cluster_centers_\n",
    "    \n",
    "    # Extracción de variables relevantes\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(Dx,Dyp_sk)\n",
    "\n",
    "    ax[aux_graphf,0].bar(columHeaders,model.feature_importances_)\n",
    "    ax[aux_graphf,0].set_title('K = ' + str(nClusters))\n",
    "    \n",
    "    ax[aux_graphf,1].scatter(Dx[:,1], Dx[:,2], c = Dyp_sk)\n",
    "    ax[aux_graphf,1].set_title('K = ' + str(nClusters))\n",
    "    ax[aux_graphf,1].set_xlabel(\"cylinders\")\n",
    "    ax[aux_graphf,1].set_ylabel(\"displacement\")\n",
    "    \n",
    "    aux_graphf += 1\n",
    "        \n",
    "    rKM_cal[str(nClusters)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "    rKM_sil[str(nClusters)] = silhouette_score(Dx, Dyp_sk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euCJ2rNbJFw4"
   },
   "source": [
    "Resultados de la importancia de los atributos para $k=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "85jv34ujJFw4",
    "outputId": "fcfaf96b-129b-4027-8f7c-10afa67d7fc3"
   },
   "outputs": [],
   "source": [
    "nClusters = 3\n",
    "modelo = KMeans(n_clusters=nClusters)\n",
    "# Se aprende el \n",
    "modelo = modelo.fit(Dx)\n",
    "X = Dx\n",
    "Y = modelo.labels_\n",
    "\n",
    "plt.subplot()\n",
    "plot_silhouettes(X,Y)\n",
    "\n",
    "mostrarAtributosRelevantes(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmUyis1ZJFw_"
   },
   "source": [
    "### RESULTADOS\n",
    "\n",
    "El número de cilindros parace ser una variable muy decisiva a la hora de asignar una muestra a un cluster, si observamos los gráficos de la distribución de los parámetros cilindros y desplazamiento de instancias respecto a los clusters, el gráfico con más sentido es el de la ejecución con $k=3$, que se corresponde con nuestras observaciones anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0U3InBaiJFxA"
   },
   "source": [
    "# Clustering Jerárquico Aglomerativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5472
    },
    "colab_type": "code",
    "id": "kacLR83bJFxB",
    "outputId": "96b2bd01-1f87-42af-e12e-ea47c5071b05"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "modelo_single = linkage(Dx, 'single')   # disimilitud mínima\n",
    "modelo_completo = linkage(Dx, 'complete') # disimilitud máxima\n",
    "modelo_average = linkage(Dx, 'average')  # disimilitud media\n",
    "\n",
    "ag_KM_cal = {}\n",
    "ag_KM_sil = {}\n",
    "plt.figure(figsize=(50, 20))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo_single)\n",
    "plt.show()\n",
    "for nClusters in range(2,6):\n",
    "    result = cut_tree(modelo_single, n_clusters=nClusters).flatten()\n",
    "    Dyp_sk = result    \n",
    "    ag_KM_cal[str(nClusters)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "    ag_KM_sil[str(nClusters)] = silhouette_score(Dx, Dyp_sk)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(ag_KM_cal.keys(), ag_KM_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_title(\"SINGLE\")\n",
    "ax.set_xlabel(\"Parámetros (Número de clusters)\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(ag_KM_sil.keys(), ag_KM_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_title(\"SINGLE\")\n",
    "ax.set_xlabel(\"Parámetros (Número de clusters)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")\n",
    "\n",
    "\n",
    "ag_KM_cal = {}\n",
    "ag_KM_sil = {}\n",
    "plt.figure(figsize=(50, 20))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo_completo)\n",
    "plt.show()\n",
    "for nClusters in range(2,6):\n",
    "    result = cut_tree(modelo_completo, n_clusters=nClusters).flatten()\n",
    "    Dyp_sk = result    \n",
    "    ag_KM_cal[str(nClusters)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "    ag_KM_sil[str(nClusters)] = silhouette_score(Dx, Dyp_sk)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(ag_KM_cal.keys(), ag_KM_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_title(\"COMPLETE\")\n",
    "ax.set_xlabel(\"Parámetros (Número de clusters)\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(ag_KM_sil.keys(), ag_KM_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_title(\"COMPLETE\")\n",
    "ax.set_xlabel(\"Parámetros (Número de clusters)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")\n",
    "\n",
    "\n",
    "ag_KM_cal = {}\n",
    "ag_KM_sil = {}    \n",
    "plt.figure(figsize=(50, 20))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo_average)\n",
    "plt.show()\n",
    "\n",
    "for nClusters in range(2,6):\n",
    "    result = cut_tree(modelo_average, n_clusters=nClusters).flatten()\n",
    "    Dyp_sk = result    \n",
    "    ag_KM_cal[str(nClusters)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "    ag_KM_sil[str(nClusters)] = silhouette_score(Dx, Dyp_sk)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(ag_KM_cal.keys(), ag_KM_cal.values(), linestyle='-', marker='o')\n",
    "ax.set_title(\"AVERAGE\")\n",
    "ax.set_xlabel(\"Parámetros (Número de clusters)\")\n",
    "ax.set_ylabel(\"Medida de Calinski-Harabasz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "ax.plot(ag_KM_sil.keys(), ag_KM_sil.values(), linestyle='-', marker='o')\n",
    "ax.set_title(\"AVERAGE\")\n",
    "ax.set_xlabel(\"Parámetros (Número de clusters)\")\n",
    "ax.set_ylabel(\"Medida de ancho de silueta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8111XBAnJFxF"
   },
   "source": [
    "### RESULTADOS\n",
    "\n",
    "Tal y como con el K-MEANS parace que un $k$ para los algoritmos aglomerativos se comporta mejor que uno alto\n",
    "\n",
    "Destacar la mejora del aglomerativo de distancia completa y media con un $k=3$ que mejora significativamente el corte para $k=2$\n",
    "\n",
    "A continuación mostramos gráficamente los resultados para el algoritmo aglomerativo uno mejores resultados (Average con 3 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cut_tree(modelo_average, n_clusters=3).flatten()\n",
    "Dyp_sk = result\n",
    "\n",
    "plot_silhouettes(Dx,Y)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95Xm9IwAJFxF"
   },
   "source": [
    "## AGRUPAMIENTO ESPECTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "colab_type": "code",
    "id": "dXim6FNEJFxH",
    "outputId": "6e9833d1-6bb7-4b46-f55e-dc134f17c8a3"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "solucionsD = []\n",
    "for nClusters in range(2,6):\n",
    "    for knn in range(5,25,1):\n",
    "        clustering = SpectralClustering(n_clusters = nClusters, affinity = 'nearest_neighbors', n_neighbors = knn, random_state = 0).fit(Dx)\n",
    "        result = clustering.labels_\n",
    "        if len(set(result)) != 0:\n",
    "            solucionsD.append([ knn, nClusters,len(set(result)),silhouette_score(Dx,result),calinski_harabaz_score(Dx, result)])\n",
    "        \n",
    "df = pd.DataFrame(solucionsD,columns=['knn', 'nClusters', 'clusters', 'silhouette', 'calinski'])\n",
    "\n",
    "sns.relplot(x=\"knn\", y=\"silhouette\",kind='line', hue='nClusters', data=df)\n",
    "sns.relplot(x=\"knn\", y=\"calinski\",kind='line', hue='nClusters', data=df)\n",
    "\n",
    "print(\"Rank by calinski\")\n",
    "print(df.sort_values(\"calinski\",ascending=False).iloc[0:10])\n",
    "\n",
    "print(\"\\nRank by silhouette\")\n",
    "print(df.sort_values(\"silhouette\",ascending=False).iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctc-KEM1JFxJ"
   },
   "source": [
    "### RESULTADOS\n",
    "\n",
    "Para algoritmo espectral los resultados mejoran cuanto mayor sea el parámetro hasta llegar a $knn=10$, que se estanca.\n",
    "\n",
    "Respecto al parámetro del número de clústers n_clusters, como en los algoritmos anteriores da mejores resultados con valores bajos $k=2$ y $k=3$ \n",
    "\n",
    "Mostramos resultados para la mejor configuración (3 clusters, 10 vecinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = SpectralClustering(n_clusters = 3, affinity = 'nearest_neighbors', n_neighbors = 10, random_state = 0).fit(Dx)\n",
    "result = clustering.labels_\n",
    "\n",
    "plot_silhouettes(Dx,result)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmMuowD_JFxJ"
   },
   "source": [
    "# Agrupamiento basado en densidad - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "colab_type": "code",
    "id": "hxqlmofBJFxK",
    "outputId": "bb718b40-a11a-4e49-e8b0-b6cfe0d596a4"
   },
   "outputs": [],
   "source": [
    "solucionsD = []\n",
    "for nSamples in np.arange(10,200,20):\n",
    "    for nEps in np.arange(0.05,1,0.05):\n",
    "        clustering = DBSCAN(eps=nEps, min_samples=nSamples).fit(Dx)\n",
    "        result = clustering.labels_\n",
    "        if len(set(result)) <= 1:\n",
    "            continue\n",
    "        solucionsD.append([ nSamples,nEps,len(set(result)),silhouette_score(Dx,result),calinski_harabaz_score(Dx, result)])\n",
    "\n",
    "df = pd.DataFrame(solucionsD,columns=['nSamples', 'nEps', 'clusters', 'silhouette', 'calinski'])\n",
    "\n",
    "sns.relplot(x=\"nEps\", y=\"silhouette\",kind='line', hue=\"nSamples\", data=df)\n",
    "sns.relplot(x=\"nEps\", y=\"calinski\",kind='line', hue=\"nSamples\", data=df) \n",
    "\n",
    "print(\"Rank by calinski\")\n",
    "print(df.sort_values(\"calinski\",ascending=False).iloc[0:10])\n",
    "\n",
    "print(\"\\nRank by silhouette\")\n",
    "print(df.sort_values(\"silhouette\",ascending=False).iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8I016cClJFxM"
   },
   "source": [
    "### RESULTADOS\n",
    "\n",
    "Para el algoritmo DBSCAN los valores altos de sus parámetros dan buenos resultados para los valores de $minSamples>120$. Cuanto más ejemplos tiene el algoritmo más tarda en dar resultados con $eps's$ pequeños.\n",
    "\n",
    "Tras las pruebas realizadas, se concluye que los mejores resultados son para $0.35<eps<0.55$\n",
    "\n",
    "Las mejores ejecuciones de este algoritmo han generado 2 clusters\n",
    "\n",
    "Mostramos resultados para 10 ejemplos y 0.4 de eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=0.4, min_samples=10).fit(Dx)\n",
    "result = clustering.labels_\n",
    "\n",
    "plot_silhouettes(Dx,result)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BT5-8eqJFxM"
   },
   "source": [
    "# Agrupamiento basado en densidad - Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "colab_type": "code",
    "id": "F-evJgvOJFxN",
    "outputId": "41145980-6b60-4e71-aa1f-6e1799899653"
   },
   "outputs": [],
   "source": [
    "solucionsD = []\n",
    "for nBandwidth in np.arange(0.05,1,0.05):\n",
    "    vBandwidth = nBandwidth\n",
    "    clustering = MeanShift(bandwidth = vBandwidth).fit(Dx)\n",
    "    \n",
    "    result = clustering.labels_\n",
    "    if np.sum(result) != 0:\n",
    "        solucionsD.append([nBandwidth,len(set(result)),silhouette_score(Dx,result),calinski_harabaz_score(Dx, result)])    \n",
    "\n",
    "df = pd.DataFrame(solucionsD,columns=['nBandwidth', 'clusters', 'silhouette', 'calinski'])\n",
    "\n",
    "sns.relplot(x=\"nBandwidth\", y=\"silhouette\",kind='line', data=df)\n",
    "sns.relplot(x=\"nBandwidth\", y=\"calinski\",kind='line', data=df) \n",
    "\n",
    "print(\"Rank by calinski\")\n",
    "print(df.sort_values(\"calinski\",ascending=False).iloc[0:10])\n",
    "\n",
    "print(\"\\nRank by silhouette\")\n",
    "print(df.sort_values(\"silhouette\",ascending=False).iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5p3QtWRJFxO"
   },
   "source": [
    "### RESULTADOS\n",
    "\n",
    "Para este algoritmo los resultados son bastante buenos. El valor del parámetro $bandwidth$ comprendido entre $0.4$ y $0.45$ genera 3 clusters con buenos resultados\n",
    "\n",
    "Mostramos resultados para bandwidth de 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XumPHpm6JFxP"
   },
   "outputs": [],
   "source": [
    "clustering = MeanShift(bandwidth = 0.4).fit(Dx)\n",
    "result = clustering.labels_\n",
    "\n",
    "plot_silhouettes(Dx,result)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRwq375vWL1B"
   },
   "source": [
    "# Agrupamiento basado en densidad - Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3689
    },
    "colab_type": "code",
    "id": "tvz-RVjQJFxQ",
    "outputId": "d023a2c6-3364-4e09-cb2a-65aae83bd402"
   },
   "outputs": [],
   "source": [
    "mSimilitud = euclidean_distances(Dx)\n",
    "mSimilitud = -mSimilitud**2\n",
    "\n",
    "rAffinity_cal = {}\n",
    "rAffinity_sil = {}\n",
    "\n",
    "solucionsD = []\n",
    "\n",
    "for pref in np.arange(100,200,10):\n",
    "    for factor in np.arange(0.6,0.91,0.1):\n",
    "        preferencia = np.median(mSimilitud) * pref\n",
    "        np.fill_diagonal(mSimilitud, preferencia)\n",
    "        modelo = AffinityPropagation(preference=preferencia, damping=factor)\n",
    "        Dyp_sk = modelo.fit_predict(Dx)\n",
    "        # Condición para parar la iteración\n",
    "        if np.max(Dyp_sk) <= 0 or np.max(Dyp_sk) >= (len(Dx)-1):\n",
    "            print(\"Error: pref: %d, factor: %f \" %(pref,factor))\n",
    "            break\n",
    "            \n",
    "        rAffinity_cal[str(pref) + '_' + str(factor)] = calinski_harabaz_score(Dx, Dyp_sk)\n",
    "        rAffinity_sil[str(pref) + '_' + str(factor)] = silhouette_score(Dx, Dyp_sk)        \n",
    "        \n",
    "        result = Dyp_sk\n",
    "        solucionsD.append([ preferencia,factor,len(set(result)),silhouette_score(Dx,result),calinski_harabaz_score(Dx, result)])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(solucionsD,columns=['preferencia', 'factor' ,'clusters', 'silhouette', 'calinski'])  \n",
    "\n",
    "sns.relplot(x=\"factor\", y=\"silhouette\",kind='line', hue=\"preferencia\", data=df)\n",
    "sns.relplot(x=\"factor\", y=\"calinski\",kind='line', hue=\"preferencia\", data=df)\n",
    "\n",
    "print(\"Rank by calinski\")\n",
    "print(df.sort_values(\"calinski\",ascending=False).iloc[0:10])\n",
    "\n",
    "print(\"\\nRank by silhouette\")\n",
    "print(df.sort_values(\"silhouette\",ascending=False).iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTADOS\n",
    "\n",
    "Para este algoritmo la enpezamos a tener resultados buenos a partir de $factor>0.65$ y con $preferencia>-60$.\n",
    "\n",
    "A partir de éstos valores los resultados parecen estabilizarse. Todas las ejecuciones buenas han dado un número de clusters igual a 2\n",
    "\n",
    "Realizamos un ejemplo de los valores con preferencia de (-50) y factor de 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = AffinityPropagation(preference=-50, damping=0.6)\n",
    "Dyp_sk = modelo.fit_predict(Dx)\n",
    "result = Dyp_sk\n",
    "\n",
    "plot_silhouettes(Dx,result)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4g4ftT5WJCV"
   },
   "source": [
    "# Mixtura de Gaussianas y algoritmo EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solucionsD = []\n",
    "for componentes in range(2,6):\n",
    "    for iters in range(100,400,10):\n",
    "        # Se inicializa el método con el número de clústeres (componentes) a buscar\n",
    "        modelo = GaussianMixture(n_components = componentes, max_iter = iters)\n",
    "        # Se aprende el modelo\n",
    "        modelo = modelo.fit(Dx)\n",
    "        # Se predicen las asignaciones a clústeres\n",
    "        Dyp_sk = modelo.predict(Dx)\n",
    "        result = Dyp_sk\n",
    "\n",
    "        solucionsD.append([ componentes,iters,len(set(result)),silhouette_score(Dx,result),calinski_harabaz_score(Dx, result)])\n",
    "\n",
    "df = pd.DataFrame(solucionsD,columns=['componentes', 'iters' ,'clusters', 'silhouette', 'calinski'])  \n",
    "\n",
    "sns.relplot(x=\"iters\", y=\"silhouette\",kind='line', hue=\"componentes\", data=df)\n",
    "sns.relplot(x=\"iters\", y=\"calinski\",kind='line', hue=\"componentes\", data=df)\n",
    "\n",
    "print(\"Rank by calinski\")\n",
    "print(df.sort_values(\"calinski\",ascending=False).iloc[0:10])\n",
    "\n",
    "print(\"\\nRank by silhouette\")\n",
    "print(df.sort_values(\"silhouette\",ascending=False).iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTADOS\n",
    "\n",
    "Resultado interesante con este algoritmo ya que se producen dos fenomenos intereseantes al aumentar el número de iteraciones para los valores de componentes 2 y 3.\n",
    "\n",
    "Para 2, 4 y 5 componentes las medidas reproducen un comportamiento oscilador cuando aumentamos el número de iteraciones (entre 150 y 300).\n",
    "\n",
    "Para 3 componentes las medidas parecen estabilizarse.\n",
    "Las mejores medidas de silueta se obtienen con 3 componentes y las de calinski con 3 componentes.\n",
    "\n",
    "Realizaremos una visualización con ambos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo =  GaussianMixture(n_components = 2, max_iter = 340)\n",
    "Dyp_sk = modelo.fit_predict(Dx)\n",
    "result = Dyp_sk\n",
    "\n",
    "plot_silhouettes(Dx,result)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo =  GaussianMixture(n_components = 3, max_iter = 340)\n",
    "Dyp_sk = modelo.fit_predict(Dx)\n",
    "result = Dyp_sk\n",
    "\n",
    "plot_silhouettes(Dx,result)\n",
    "mostrarAtributosRelevantes(Dx,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Actividad_Final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
